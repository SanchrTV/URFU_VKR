## Введение

Машинное разучивание (Machine Unlearning, MU) представляет собой относительно новую область исследований в машинном обучении, направленную на избирательное удаление влияния конкретных данных из уже обученных моделей без необходимости их полного переобучения. Эта способность становится всё более важной в современных условиях, когда вопросы защиты персональных данных, безопасности систем и актуальности моделей приобретают критическое значение.
Одной из главных причин растущей значимости машинного разучивания является необходимость соблюдения высоких стандартов конфиденциальности. С принятием таких нормативных актов, как Общий регламент по защите данных (GDPR) Европейского Союза и Закон о конфиденциальности потребителей Калифорнии (CCPA), пользователи получили возможность требовать удаления их персональной информации из обученных моделей – так называемое «право быть забытым». Помимо правовых аспектов, данный подход помогает снизить риски, связанные с утечками данных и атаками на целостность обучающих наборов, например, при отравлении данных.
Не менее важной становится адаптация моделей к изменяющимся условиям. В динамичных средах данных многие обучающие примеры со временем могут устаревать или становиться нерелевантными, что негативно сказывается на качестве предсказаний. Машинное разучивание позволяет оперативно исключать такие данные из модели, сохраняя её эффективность и обеспечивая устойчивость к новым типам угроз.
Однако применение машинного разучивания сталкивается с рядом вызовов. Одной из основных проблем является сложность точного локализовать и удалить влияние конкретных данных в сложных моделях с миллионами параметров, а также необходимость минимизировать вычислительные затраты, связанные с этим процессом. Кроме того, важным аспектом остаётся разработка надёжных методов верификации – проверки того, что удаление данных действительно привело к нивелированию их влияния на модель.
Таким образом, машинное разучивание выступает как необходимый инструмент для соблюдения регуляторных требований, обеспечения безопасности и адаптации систем искусственного интеллекта к быстро меняющимся данным, несмотря на существующие технологические и вычислительные ограничения.

## Основные причины применения Machine Unlearning
Machine Unlearning предоставляет эффективный механизм для удаления влияния отдельных данных из обученных моделей без необходимости полного переобучения. Такой подход становится особенно важным по нескольким причинам:
	1.	Защита конфиденциальности данных
С появлением нормативных актов, таких как GDPR и CCPA, пользователи получили возможность требовать удаления своих персональных данных из систем искусственного интеллекта. Вместо затратного полного переобучения, методы Machine Unlearning позволяют выборочно удалять нужную информацию, минимизируя вычислительные затраты и обеспечивая соблюдение «права быть забытым» [Xu et al., 2023; Qu et al., 2023].
	2.	Безопасность моделей
Модели машинного обучения часто становятся целью атак, при которых злоумышленники внедряют вредоносные данные для изменения поведения модели (data poisoning). Применяя методы разучивания, можно обнаруживать и удалять такие данные, что позволяет повысить устойчивость системы к манипуляциям и снижает риск компрометации модели [Mehta et al., 2023; Guo et al., 2023].
	3.	Адаптация к изменяющимся данным
В условиях динамичных данных часть обучающего набора может со временем устаревать или становиться нерелевантной. Machine Unlearning позволяет оперативно исключать такие данные из модели, обеспечивая её адаптацию к новым условиям и поддержание высокой точности предсказаний без необходимости повторного полного обучения [Guo et al., 2023; Bourtoule et al., 2021].

## Классические подходы к Machine Unlearning
Классические методы машинного разучивания можно разделить на две основные категории: точное и приближенное разучивание. Каждый из этих подходов имеет свои особенности, преимущества и ограничения в зависимости от сложности модели и требований к эффективности удаления влияния данных.

### Точное разучивание (Exact Unlearning)
Подходы точного разучивания направлены на полное устранение влияния удаляемых данных так, чтобы модель после разучивания вела себя так, как если бы эти данные никогда не использовались при обучении. Среди методов точного разучивания можно выделить:
	•	SISA (Sharded, Isolated, Sliced, and Aggregated Training):
Этот алгоритм разбивает обучающие данные на изолированные сегменты, что позволяет локально удалять выбранные данные без необходимости полного переобучения всей модели. Такой подход минимизирует вычислительные затраты, обеспечивая точное разучивание только затронутых сегментов [Bourtoule et al., 2021].
	•	DeltaGrad:
Метод, основанный на концепции обратного обучения (Reverse Learning), при котором удаляемые данные используются для увеличения ошибки модели. В результате влияние этих данных нивелируется, и модель приближается к состоянию, как если бы данные никогда не присутствовали в обучающем наборе [Nguyen et al., 2022].

### Приближенное разучивание (Approximate Unlearning)
Приближенное разучивание ориентировано на снижение влияния определённых данных без гарантии полного их устранения. Такой подход часто выбирается для сложных моделей, например, глубоких нейросетей, где полное разучивание может быть вычислительно слишком затратным.
	•	Сертифицированное удаление данных (Certified Data Removal):
Этот метод использует модифицированные градиентные обновления и стохастические возмущения, чтобы уменьшить влияние удаляемых данных. Несмотря на то, что влияние не устраняется полностью, достигается приемлемый баланс между эффективностью разучивания и сохранением производительности модели [Guo et al., 2023].
	•	Лагранжева оптимизация:
Дополнительный подход, предложенный Golatkar et al. (2020), основывается на оптимизации с использованием лагранжевых множителей для избирательного удаления влияния определённых параметров модели. Этот метод позволяет адаптивно корректировать веса, минимизируя нежелательное влияние удаляемых данных, что особенно полезно при работе с большими моделями [Golatkar et al., 2020].

## Основные вызовы классического Machine Unlearning
Несмотря на значительный прогресс в разработке методов машинного разучивания, существует ряд фундаментальных вызовов, которые необходимо решить для успешного применения этих технологий в реальных системах. Эти вызовы не только отражают сложности, связанные с текущими архитектурами и алгоритмами, но и предвещают направления для дальнейших исследований и разработки новых подходов.

### Зависимость данных
Современные модели машинного обучения учатся на сложных корреляциях между обучающими примерами. При удалении отдельных записей или сегментов данных существует риск нарушения выявленных закономерностей, что может привести к снижению точности и ухудшению общего качества модели. Эффективное разучивание требует точного понимания взаимосвязей внутри обучающего набора, чтобы гарантировать, что удаление информации не повлияет негативно на производительность модели.

### Сложность современных моделей
Глубокие нейросети и другие современные архитектуры содержат миллионы параметров, что существенно усложняет задачу локализации и удаления влияния конкретных данных. Даже при использовании методов точного разучивания, таких как SISA или DeltaGrad, вызов заключается в том, чтобы изолировать вклад каждого обучающего примера и обеспечить его полное исключение без нарушения структуры модели. Эта проблема особенно актуальна для масштабных систем, где даже небольшие изменения могут иметь далеко идущие последствия.

### Вычислительная сложность
Многие подходы к машинному разучиванию, особенно точные методы, требуют значительных вычислительных ресурсов. Повторное обучение части модели или корректировка весов с целью удаления влияния конкретных данных могут быть крайне затратными с точки зрения времени и вычислительной мощности. Это делает применение данных методов ограниченным для крупных или ресурсоемких систем, где оптимизация процесса разучивания становится критически важной.

### Верификация разучивания
Одним из ключевых вызовов является верификация того, что данные действительно были удалены из модели. Необходимо разработать надежные методики и метрики, которые позволят проверить, что влияние удаляемой информации было минимизировано или полностью устранено. Существующие подходы включают анализ параметров модели до и после разучивания, применение атак на членство и даже использование криптографических доказательств. Однако разработка универсальных и эффективных методов верификации остается сложной задачей, требующей дальнейших исследований.

## Методы верификации машинного разучивания
Поскольку эффективность машинного разучивания напрямую зависит от того, насколько полно удалось устранить влияние удалённых данных, разработка надёжных методов верификации становится неотъемлемой частью процесса. В этой связи применяются несколько ключевых подходов, позволяющих оценить степень успешности разучивания и подтвердить, что модель действительно утратила нежелательное влияние исходных данных.

### Анализ параметров модели до и после разучивания
Один из базовых методов верификации заключается в сравнительном анализе параметров модели до и после процесса разучивания. Сравнивая веса и статистические характеристики модели, можно оценить, насколько изменение параметров соответствует ожидаемому эффекту удаления информации. Такой подход позволяет количественно определить, насколько влияние удалённых данных было минимизировано, а также выявить возможные отклонения в работе модели.

### Атаки на членство (Membership Inference Attacks)
Другим эффективным инструментом проверки является применение атак на членство. Эти атаки позволяют определить, содержатся ли в обучающем множестве удалённые данные или их влияние сохранилось. Если модель после разучивания всё ещё демонстрирует признаки «запоминания» данных, которые должны быть исключены, атака на членство выявит это, что станет сигналом о недостаточной эффективности разучивания. Таким образом, данный метод помогает не только оценить степень успешности процесса, но и обнаружить потенциальные уязвимости.

### Криптографические доказательства разучивания
Для повышения уровня доверия к процессу разучивания и обеспечения прозрачности его результатов применяются криптографические методы. Криптографические доказательства разучивания позволяют сформировать математически обоснованные гарантии того, что модель действительно утратила информацию о конкретных данных. Такой подход особенно важен в контексте соблюдения нормативных требований, поскольку обеспечивает независимую и верифицируемую оценку успешности разучивания.

## Перспективы развития Machine Unlearning
Будущие исследования в области машинного разучивания направлены на преодоление существующих ограничений и создание методов, способных интегрироваться в масштабируемые AI-системы. В частности, актуальными направлениями являются:
	1.	Интеграция в масштабируемые AI-системы.
Для применения методов разучивания в реальных, динамичных системах необходимо разработать алгоритмы, способные работать в условиях децентрализованного и потокового обучения. Это особенно важно для федеративных систем, где данные распределены между множеством устройств, и требуется удаление нежелательной информации без полной перестройки модели [Guo et al., 2023; Xu et al., 2023].
	2.	Разработка более эффективных методов разучивания для глубоких нейросетей.
Сложность современных архитектур, таких как Transformer, делает задачу точного удаления влияния отдельных данных крайне сложной. Перспективное направление исследований заключается в создании гибридных методов, сочетающих точное и приближенное разучивание, которые позволят не только локализовать вклад нежелательной информации, но и эффективно её удалить без ущерба для общей производительности модели [Bourtoule et al., 2021; Nguyen et al., 2022].
	3.	Автоматизированное удаление информации в потоковом обучении.
Развитие технологий онлайн-обучения требует внедрения механизмов, позволяющих динамически обновлять модель, интегрируя новые данные и одновременно удаляя устаревшие или конфиденциальные сведения. Автоматизированные системы разучивания, способные работать в режиме реального времени, позволят существенно сократить вычислительные затраты и обеспечить непрерывную адаптацию моделей к изменяющимся условиям [Xu et al., 2023].
	4.	Регуляторные перспективы и необходимость стандартизации.
Усиление нормативных требований, таких как GDPR и CCPA, требует создания проверяемых и прозрачных методов разучивания. Разработка единых стандартов и протоколов для реализации и оценки методов Machine Unlearning позволит повысить доверие пользователей и обеспечить юридическую ответственность AI-систем. В этой связи будущие исследования должны уделять внимание разработке надежных метрик, отражающих как эффективность удаления целевой информации, так и сохранение общих способностей модели [Qu et al., 2023].

Таким образом, дальнейшее развитие Machine Unlearning будет способствовать созданию более безопасных, адаптивных и конфиденциальных AI-систем, способных эффективно управлять знаниями в условиях постоянного изменения данных. Эти направления создают основу для перехода к следующему разделу, посвящённому применению методов разучивания в больших языковых моделях (LLMs), где вопросы сохранения полезной информации и избирательного удаления нежелательных знаний становятся особенно актуальными [Guo et al., 2023; Bourtoule et al., 2021].
