## ВВЕДЕНИЕ

Современные методы машинного обучения активно применяются в различных областях науки и техники, обеспечивая высокую точность решений и автоматизацию сложных процессов. Однако одним из ключевых вызовов в развитии этих технологий является необходимость избирательного удаления информации из обученных моделей. Это связано как с требованиями регуляторов по защите персональных данных, так и с задачами адаптации моделей к изменяющимся условиям и устранения ошибок в обучающих данных. В ответ на эти вызовы в последние годы активно развивается направление **Machine Unlearning** (машинное отучение), которое предлагает методы для корректного удаления влияния отдельных данных без необходимости полного переобучения модели.

Основная сложность машинного отучения заключается в том, что знания в больших языковых моделях не локализованы в отдельных параметрах, а распределены по всей их структуре. Это делает процесс целевого удаления информации нетривиальной задачей, требующей разработки специализированных алгоритмов. В рамках данной практики рассматриваются современные методы отучения, включая **Knowledge Editing** и **Simplifyed Negative Preference Optimization (SimNPO)**, позволяющие обеспечивать удаление данных при минимальном влиянии на общее качество больших языковых моделей.

**Актуальность** работы обусловлена необходимостью создания эффективных алгоритмов машинного отучения, обеспечивающих выполнение требований регуляторов (например, GDPR), защиту моделей от атак (data poisoning) и адаптацию к регулярно обновляющимся данным. В настоящее время большинство существующих методов либо требуют полного переобучения модели, что является вычислительно затратным процессом, либо не гарантируют точного удаления данных. Разработка и анализ более эффективных стратегий удаления знаний является важной задачей для обеспечения безопасности и надежности больших языковых моделей.

**Объект** исследования: методы машинного отучения для больших языковых моделей.

**Предмет** исследования: принципы и алгоритмы удаления информации из обученных моделей без их полного переобучения.

**Цель практики**: изучение, анализ и реализация методов машинного отучения на примере моделей, работающих с текстовыми данными.

Для достижения поставленной цели необходимо выполнить следующие задачи:
1. Провести анализ существующих методов машинного отучения, включая точное и приближенное разучивание.
2. Изучить современные подходы к удалению информации в больших языковых моделях (LLM), включая Negative Preference Optimization (NPO) и SimNPO.
3. Провести сравнение методов отучения и редактирования знаний (Knowledge Editing) с точки зрения точности удаления данных и сохранения работоспособности модели.
4. Оценить вычислительные затраты различных подходов и их применимость к реальным задачам машинного обучения.

## Анализ существующих подходов Machine Unlearning

### 1.1 Анализ классических методов Machine Unlearning

#### 1.1.1 Точное и приближенное разучивание

Методы машинного отучения направлены на избирательное удаление данных из обученных моделей без их полного переобучения. В классической литературе выделяют два основных подхода: **точное разучивание (Exact Unlearning)** и **приближенное разучивание (Approximate Unlearning)**.

Точное разучивание обеспечивает детерминированное удаление данных, гарантируя, что модель после отучения ведёт себя так, как если бы удалённые данные никогда не использовались при обучении. Среди методов точного отучения можно выделить:
- **SISA (Sharded, Isolated, Sliced, and Aggregated Training)** – метод, при котором данные разбиваются на изолированные сегменты, что позволяет локально удалять затронутые сегменты без полного переобучения модели.
- **DeltaGrad** – алгоритм, основанный на обратном градиентном обновлении, нивелирующий влияние удалённых данных за счёт корректировки параметров модели.

Приближенное разучивание ориентировано на снижение влияния определённых данных без строгой гарантии их полного устранения. Этот метод особенно актуален для глубоких нейронных сетей, где полное разучивание может быть вычислительно затратным. К основным подходам приближенного отучения относятся:
- **Сертифицированное удаление данных (Certified Data Removal)** – метод, использующий стохастические градиентные обновления для минимизации влияния удаляемых данных.
- **Лагранжева оптимизация** – способ корректировки параметров модели с минимальным вмешательством в её структуру, позволяющий избирательно устранять нежелательные данные.

#### 1.1.2 Вызовы классического машинного отучения

Несмотря на значительный прогресс в разработке методов машинного отучения, существуют ключевые вызовы, ограничивающие их широкое применение:
1. **Распределённость знаний в модели** – знания в LLM не локализованы в отдельных параметрах, а распределены по всей сети, что затрудняет их точечное удаление.
2. **Катастрофическое забывание** – удаление одних данных может привести к утрате связанных знаний и ухудшению точности модели.
3. **Высокие вычислительные затраты** – многие методы отучения требуют значительных ресурсов, что делает их непрактичными для крупных моделей.
4. **Остаточное запоминание данных** – даже после отучения удалённая информация может сохраняться в латентных представлениях модели.

Данные вызовы определяют необходимость разработки более эффективных методов отучения, способных обеспечивать высокую точность удаления данных при минимальном влиянии на структуру модели.

### 1.2 Анализ современных методов Machine Unlearning применительно к большим языковым моделями

Современные методы машинного отучения (Machine Unlearning, MU) представляют собой ключевое направление в разработке алгоритмов обработки данных, направленных на избирательное удаление информации из обученных моделей. Особое значение этот процесс приобретает в контексте больших языковых моделей, которые обладают сложной параметрической структурой и значительными вычислительными затратами.

На сегодняшний день выделяют три основные группы методов машинного отучения, применимых к LLM:
- **Методы градиентного отучения (Gradient-based Unlearning)**, основанные на направленной корректировке параметров модели для минимизации влияния удаляемых данных.
- **Методы редактирования знаний (Knowledge Editing)**, ориентированные на целенаправленную модификацию параметров модели без полного переобучения.
- **Методы приближенного отучения (Approximate Unlearning)**, использующие стохастические и оптимизационные техники для снижения вероятности генерации удалённой информации.

Рассмотрим ключевые алгоритмы в каждой из этих категорий и их применимость к большим языковым моделям.

#### Методы градиентного отучения
Одним из наиболее изучаемых методов является **Gradient Ascent (GA)**, предполагающий целенаправленное увеличение ошибки модели на удаляемых данных. Этот метод позволяет быстро исключить влияние нежелательных примеров, но может привести к деградации общей работоспособности модели. Альтернативным подходом является **Negative Preference Optimization (NPO)**, который позволяет более контролируемо снижать вероятность предсказания удаляемой информации за счёт корректировки градиентной структуры модели.

#### Методы редактирования знаний
Методы редактирования знаний обеспечивают точечное обновление информации в модели, что делает их особенно полезными для LLM. К числу таких методов относится **Rank-One Model Editing (ROME)**, который использует каузальный анализ для локального изменения параметров модели. Более масштабируемым вариантом является **Mass-Editing Memory in Transformers (MEMIT)**, позволяющий одновременно корректировать несколько параметров модели. Современные подходы к редактированию знаний обеспечивают эффективное управление содержимым модели без необходимости полного переобучения.

#### Методы приближенного отучения
Приближенные методы, такие как **Certified Data Removal**, используют модифицированные градиентные обновления для уменьшения влияния удаляемых данных. Они позволяют балансировать между эффективностью отучения и сохранением работоспособности модели. Также перспективным направлением является использование методов оптимизации, таких как **Simplified Negative Preference Optimization (SimNPO)**, который снижает вероятность генерации удалённой информации за счёт динамического регулирования параметров модели.

Современные методы машинного отучения демонстрируют высокую эффективность в задачах удаления нежелательной информации, однако их применение в контексте LLM сталкивается с рядом вызовов, включая вычислительную сложность, устойчивость к атакам повторного обучения и необходимость сохранения общей работоспособности модели. Оптимальное сочетание методов редактирования знаний и приближенного отучения является перспективным направлением дальнейших исследований.

## ЗАКЛЮЧЕНИЕ

В ходе прохождения учебной практики были выполнены следующие задачи:
	•	проведён анализ современных методов Machine Unlearning, применяемых для удаления информации из обученных моделей без их полного переобучения;
	•	рассмотрены классические подходы к машинному разучиванию, включая точное разучивание (Exact Unlearning) и приближённое разучивание (Approximate Unlearning), а также выявлены их ограничения при работе с большими языковыми моделями (LLM);
	•	исследованы современные методы отучения, такие как Negative Preference Optimization (NPO) и Simplified Negative Preference Optimization (SimNPO), их преимущества и возможности применения для работы с LLM;
	•	изучены альтернативные подходы к разучиванию, основанные на редактировании знаний в моделях (Knowledge Editing), включая методы ROME, MEMIT, MEND и PMET, позволяющие избирательно модифицировать знания модели без полного переобучения;
	•	проведён сравнительный анализ существующих методов, выявлены ключевые вызовы машинного отучения, такие как остаточное запоминание удаляемых данных (residual memorization), катастрофическое забывание (catastrophic forgetting) и сложность масштабирования методов MU для LLM.

Таким образом, цель практики достигнута. Полученные результаты позволят глубже понять механизмы управления знаниями в больших языковых моделях и будут использованы для дальнейших исследований в области эффективного и безопасного машинного отучения.
